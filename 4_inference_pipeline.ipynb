{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a17351-cdff-44fd-b681-5a63ce5ea3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdeb517-9eea-434d-bb2c-800189e4aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from joblib import load\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db346734-b3f3-4ffc-ad5b-4aa909f66217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load Whisper model\n",
    "pipe = pipeline(model=\"anggari/whisper-medium-multi\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cb3720-02f6-4fb0-9ade-9e939dda082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1aaf8e73610>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(1, 3102), activation='relu'))\n",
    "model.add(LayerNormalization()),\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, activation='softmax'))\n",
    "model.load_weights('lstm_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64be7fe-f0ec-4a02-9fc3-1fc96f03c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectorizer\n",
    "tfidf_vectorizer = load('tfidf_vectorizer_new.joblib')\n",
    "\n",
    "# Load label encoder\n",
    "label_encoder = load('label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14cc11c4-0f35-46ee-9c7e-6fb4e4286463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_DATASETS_OFFLINE '] = \"1\"\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9103f397-c0ea-4c8d-aa91-8c6ab76818d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "    num_rows: 2754\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_used=['zh-CN', 'ru-RU', 'fr-FR', 'en-US', 'de-DE']\n",
    "minds=[]\n",
    "for i in lang_used:\n",
    "    minds_data = load_dataset(\"PolyAI/minds14\", i, trust_remote_code=True)\n",
    "    minds.append(minds_data['train'])\n",
    "\n",
    "minds = concatenate_datasets(minds)\n",
    "minds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "471422a9-a363-40a3-b0af-e61b578387b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1649"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0,2754)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f83602-e5ce-4e91-b2bb-45ea9b6730dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = minds[1649]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76be70b0-c658-4ed2-b8a1-b936d9ac5424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'C:\\\\Users\\\\andre\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\482a593b1882116f1ef934ce05f74608ebffded5fe81b88e49a3d63337574cf4\\\\en-US~BALANCE\\\\602ba046bb1e6d0fbce91fd3.wav',\n",
       " 'audio': {'path': 'C:\\\\Users\\\\andre\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\482a593b1882116f1ef934ce05f74608ebffded5fe81b88e49a3d63337574cf4\\\\en-US~BALANCE\\\\602ba046bb1e6d0fbce91fd3.wav',\n",
       "  'array': array([ 0.        ,  0.        ,  0.00024414, ...,  0.00024414,\n",
       "          0.        , -0.00024414]),\n",
       "  'sampling_rate': 8000},\n",
       " 'transcription': 'what is my current bank balance',\n",
       " 'english_transcription': 'what is my current bank balance',\n",
       " 'intent_class': 4,\n",
       " 'lang_id': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be4759-6f32-42a8-a103-520ce23a0659",
   "metadata": {},
   "source": [
    "# Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7e51055-c702-4f22-952d-53d2caf8fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_double_space(text):\n",
    "    # Menghapus double space dengan regex\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def transcribe(audio):\n",
    "    text = pipe(audio)[\"text\"]\n",
    "    text = remove_double_space(text).lower()\n",
    "    text_tfidf = tfidf_vectorizer.transform([text])\n",
    "    text_dense = text_tfidf.toarray()\n",
    "    text_lstm = np.expand_dims(text_dense, axis=1)\n",
    "    y_pred = model.predict(text_lstm)\n",
    "    intent_class = np.argmax(y_pred, axis=1)\n",
    "    intent = label_encoder.inverse_transform(intent_class)\n",
    "    return text, intent_class, intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de2a325-fda8-42cc-a4aa-41a5281eacf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\python310\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 371ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('what is my current bank balance',\n",
       " array([4], dtype=int64),\n",
       " array(['balance'], dtype=object))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe(sample[\"audio\"][\"array\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
