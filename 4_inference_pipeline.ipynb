{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a17351-cdff-44fd-b681-5a63ce5ea3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1fdeb517-9eea-434d-bb2c-800189e4aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from joblib import load\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db346734-b3f3-4ffc-ad5b-4aa909f66217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(model=\"anggari/whisper-medium-multi\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cb3720-02f6-4fb0-9ade-9e939dda082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(1, 3102), activation='relu'))\n",
    "model.add(LayerNormalization()),\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5baba94-c412-41ce-9f4f-3fe0c26bb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = load('label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14cc11c4-0f35-46ee-9c7e-6fb4e4286463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_DATASETS_OFFLINE '] = \"1\"\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9103f397-c0ea-4c8d-aa91-8c6ab76818d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "    num_rows: 2754\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_used=['zh-CN', 'ru-RU', 'fr-FR', 'en-US', 'de-DE']\n",
    "minds=[]\n",
    "for i in lang_used:\n",
    "    minds_data = load_dataset(\"PolyAI/minds14\", i, trust_remote_code=True)\n",
    "    minds.append(minds_data['train'])\n",
    "\n",
    "minds = concatenate_datasets(minds)\n",
    "minds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "471422a9-a363-40a3-b0af-e61b578387b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1649"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0,2754)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8111d-d227-47e1-b5f2-ed3d73b22fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(minds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63f83602-e5ce-4e91-b2bb-45ea9b6730dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = minds[1649]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "76be70b0-c658-4ed2-b8a1-b936d9ac5424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'C:\\\\Users\\\\andre\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\482a593b1882116f1ef934ce05f74608ebffded5fe81b88e49a3d63337574cf4\\\\en-US~BALANCE\\\\602ba046bb1e6d0fbce91fd3.wav',\n",
       " 'audio': {'path': 'C:\\\\Users\\\\andre\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\482a593b1882116f1ef934ce05f74608ebffded5fe81b88e49a3d63337574cf4\\\\en-US~BALANCE\\\\602ba046bb1e6d0fbce91fd3.wav',\n",
       "  'array': array([ 0.        ,  0.        ,  0.00024414, ...,  0.00024414,\n",
       "          0.        , -0.00024414]),\n",
       "  'sampling_rate': 8000},\n",
       " 'transcription': 'what is my current bank balance',\n",
       " 'english_transcription': 'what is my current bank balance',\n",
       " 'intent_class': 4,\n",
       " 'lang_id': 4}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7e51055-c702-4f22-952d-53d2caf8fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = load('tfidf_vectorizer_new.joblib')\n",
    "\n",
    "def remove_double_space(text):\n",
    "    # Menghapus double space dengan regex\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def transcribe(audio):\n",
    "    text = pipe(audio)[\"text\"]\n",
    "    text = remove_double_space(text).lower()\n",
    "    text_tfidf = tfidf_vectorizer.transform([text])\n",
    "    text_dense = text_tfidf.toarray()\n",
    "    text_lstm = np.expand_dims(text_dense, axis=1)\n",
    "    y_pred = model.predict(text_lstm)\n",
    "    intent_class = np.argmax(y_pred, axis=1)\n",
    "    intent = label_encoder.inverse_transform(intent_class)\n",
    "    return text, intent_class, intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0de2a325-fda8-42cc-a4aa-41a5281eacf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\andre\\python310\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('what is my current rate of growth',\n",
       " array([5], dtype=int64),\n",
       " array(['business_loan'], dtype=object))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe(sample[\"audio\"][\"array\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
